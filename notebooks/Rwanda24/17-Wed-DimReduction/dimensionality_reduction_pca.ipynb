{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsoldadomagraner/TReND-CaMinA/blob/main/notebooks/Rwanda24/17-Wed-DimReduction/dimensionality_reduction_pca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0sGJoo2Jn6o"
      },
      "source": [
        "\n",
        "# **Dimensionality Reduction: PCA**\n",
        "<!--[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/trendinafrica/TReND-CaMinA/blob/main/notebooks/Rwanda24/17-Wed-DimReduction/dimensionality_reduction_pca.ipynb)-->\n",
        "\n",
        "\n",
        "<img align=\"left\" width=\"100\" src=\"https://raw.githubusercontent.com/trendinafrica/TReND-CaMinA/main/images/CaMinA_logo.png\">\n",
        "\n",
        "### **TReND-CaMinA: Computational Neuroscience and Machine Learning basics school, Rwanda 2024**\n",
        "#### **Content creators:** Byron Yu and Joana Soldado Magraner, Carnegie Mellon University\n",
        "\n",
        "---\n",
        "\n",
        "###**Learning objectives:**\n",
        "* Use PCA for real brain data exploration\n",
        "* Gain intuitions about high-dimensional neural data\n",
        "\n",
        "The dataset for the following problems is contained in data_for_exercises.mat, on our Google Drive. You will find the following variable:\n",
        "\n",
        "Xplan: a 728 x 97 matrix of real data, where each row is a spike count vector across 97 simultaneously-recorded neurons in dorsal premotor cortex (PMd) of a macaque monkey $^1$. Spike counts are taken in a 200 ms bin while the monkey is planning to make an arm reach. There are 91 trials for each of 8 reaching angles, for a total of 728 trials. Trials 1 to 91 correspond to reaching angle 1, trials 92 to 182 correspond to reach angle 2, etc.\n",
        "\n",
        "1. The neural data have been generously provided by the laboratory of Prof. Krishna Shenoy at Stanford University. The data are to be used exclusively for educational purposes in this course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeldCG_61JgH"
      },
      "outputs": [],
      "source": [
        "# run this if you want to import your data directly from googledrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyqmjOEMhrD5"
      },
      "source": [
        "#### Run the following cell to import all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MHQqSTRWPzF6"
      },
      "outputs": [],
      "source": [
        "# %pip install ipympl\n",
        "%matplotlib widget\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "from scipy import linalg\n",
        "import scipy.io as spio\n",
        "\n",
        "# from google.colab import output\n",
        "# output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4DxILEczoI"
      },
      "source": [
        "\n",
        "#### Load the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzVM1OttVI7U"
      },
      "outputs": [],
      "source": [
        "# Import data from googledrive\n",
        "# datapath  = '/content/drive/MyDrive/TReND-CaMinA teaching materials/Rwanda24/17-Wed-DimReduction/'\n",
        "# Alternatively, upload the data into colab and set:\n",
        "datapath  = ''\n",
        "datafile  = 'data_for_exercises.mat'\n",
        "\n",
        "# Load the Matlab format .mat data into Python\n",
        "mat   = spio.loadmat(datapath + datafile, squeeze_me=True)\n",
        "Xplan = mat['Xplan']\n",
        "\n",
        "plan_data_dims = Xplan.shape\n",
        "n  = plan_data_dims[0]\n",
        "d  = plan_data_dims[1]\n",
        "\n",
        "print('Xplan dims (N,D) N=samples/datapoints D=neurons/features')\n",
        "print(plan_data_dims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRmVv0ZiaEr"
      },
      "source": [
        "# 1. Visualization of high-dimensional neural activity using PCA\n",
        "\n",
        "We will apply PCA to the matrix of data Xplan $\\in \\mathbb{R}^{N\\times D}$ to gain some intuition about plan activity in PMd. The data points are $\\boldsymbol{x}_n \\in \\mathbb{R}^D$ (n = 1, ..., N), where D = 97 is the data dimensionality (neurons)\n",
        "and N = 728 is the number of data points (trials).\n",
        "\n",
        "But first, let's take a look at the data. Do you see any obvious patterns?\n",
        "\n",
        "Remember that there are 91 trials for each of 8 reaching angles, for a total of 728 trials. Trials 1 to 91 correspond to reaching angle 1, trials 92 to 182 correspond to reach angle 2, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quYVYL9WDTrP"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "b   = plt.imshow(Xplan.T, aspect='auto')\n",
        "fig.colorbar(b)\n",
        "plt.xticks(range(0,n,91),range(1,n+1,91))\n",
        "plt.ylabel('Neuron #')\n",
        "plt.xlabel('Trial #')\n",
        "plt.title('Heat map of neural population spike counts')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXZvEXhaDWcm"
      },
      "source": [
        "[EXERCISE 1a] Run PCA on the high-dimensional Xplan data. You can do this simply by diagonalizing the sample covariance matrix of the data $S = 1/N \\sum_n (\\boldsymbol{x}_n-\\boldsymbol{\\mu})(\\boldsymbol{x}_n-\\boldsymbol{\\mu})^{\\intercal} $, where $\\boldsymbol{\\mu}$ is the sample mean of the data, $\\boldsymbol{\\mu} = 1/N \\sum_n \\boldsymbol{x}_n$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krK-vnTwDFBB"
      },
      "outputs": [],
      "source": [
        "# first find the mean of the data\n",
        "mu = np.mean(Xplan,axis=0)\n",
        "\n",
        "# now compute the data covariance\n",
        "# don't forget to center your data first!\n",
        "Xplan_centered = Xplan - mu\n",
        "\n",
        "# now you can compute the covariance\n",
        "cov = (1/n) * Xplan_centered.T @ Xplan_centered\n",
        "diff = cov - np.cov(Xplan_centered.T)\n",
        "print(\"max relative error of cov = \" + str(diff.max()/cov.flatten()[diff.argmax()]))\n",
        "\n",
        "# perform the eigendecomposition of the data covariance\n",
        "D, U = np.linalg.eig(cov) # D = vector of eigenvalues, U = eigenvectors matrix\n",
        "\n",
        "# make sure the eigenvalues are sorted (in descending order)\n",
        "indx = np.argsort(D)[::-1]\n",
        "D = D[indx]\n",
        "\n",
        "# arrange the eigenvectors according to the magnitude of the eigenvalues\n",
        "U = U[:,indx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0IQVhpaLW6S"
      },
      "outputs": [],
      "source": [
        "# #@title Double click to see solution {display-mode: \"form\" }\n",
        "# # first find the mean of the data\n",
        "# mu = np.mean(Xplan,axis=0)\n",
        "# n  = Xplan.shape[0]\n",
        "# p  = Xplan.shape[1]\n",
        "\n",
        "# # now compute the data covariance\n",
        "# Xplan_centered = Xplan-mu                         # don't forget to center your data first!\n",
        "# cov = (1/n) * Xplan_centered.T @ Xplan_centered   # now you can compute the covariance\n",
        "# # perform eigendecomposition of the data covariance\n",
        "# D, U = np.linalg.eig(cov) # D = vector of eigenvalues, U = eigenvectors matrix\n",
        "\n",
        "# # make sure the eigenvalues are sorted (in descending order)\n",
        "# indx = np.argsort(D)[::-1]\n",
        "# D    = D[indx]\n",
        "\n",
        "# # arrange the eigenvectors according to the magnitude of the eigenvalues\n",
        "# U = U[:,indx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYm7wGEFZjPD"
      },
      "source": [
        "Plot the square-rooted eigenvalue spectrum. If you had to identify an elbow in the eigenvalue spectrum, how many dominant eigenvalues would there be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okhqZPBlyabP"
      },
      "outputs": [],
      "source": [
        "#plot the square-root eigenvalue spectrum\n",
        "fig = plt.figure()\n",
        "plt.plot(np.sqrt(D),'-o',color='k')\n",
        "plt.xlabel('dimensions')\n",
        "plt.ylabel('square-rooted eigenvalues')\n",
        "plt.title('Square-root eigenvalue spectrum')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT9v7vNAQreg"
      },
      "source": [
        "Note that there is an elbow (a big drop) after the 3rd eigenvalue. This indicates that the first three dimensions capture most of the data variance.\n",
        "\n",
        "[EXERCISE 1b] What percentage of the overall data variance is captured by the top 3 principal components?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X53lfY9qN_Kj"
      },
      "outputs": [],
      "source": [
        "# Hint, this is a function of the eigenavlues D\n",
        "# k = 3\n",
        "# percent_var = 100*D[:k].sum()/D.sum()\n",
        "# print(f'percent variance explained k={k}: {percent_var}')\n",
        "\n",
        "percent_vars = 100 * D.cumsum() / D.sum()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(percent_vars,'-o',color='k')\n",
        "plt.xlabel('dimensions')\n",
        "plt.ylabel('Percent variance explained')\n",
        "plt.title('Percentage of variance explained by Principle components')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkOjD4cDScod"
      },
      "outputs": [],
      "source": [
        "# #@title Double click to see solution {display-mode: \"form\" }\n",
        "# # Hint, this is a function of the eigenvectors D\n",
        "# percent_var = 100 * np.sum(D[0:3])/np.sum(D)\n",
        "# print('percent variance explained = ', percent_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCZS-zGyT7F8"
      },
      "source": [
        "For the purposes of visualization, consider the PC space defined by the 3 eigenvectors.\n",
        "\n",
        "[EXERCISE 1c] Project the data points $\\boldsymbol{x}_n \\in \\mathbb{R}^D$ into the three-dimensional PC space. The projections are the PC scores $\\boldsymbol{z}_n \\in \\mathbb{R}^3$, where $z_n^i = \\boldsymbol{u}_i^{\\intercal} (\\boldsymbol{x}_n - \\boldsymbol{\\mu})$, $i=1,2,3$. Plot the projected points, and color each dot appropriately according to reaching angle (there should be a total of 728 dots). Use your mouse to rotate the three-dimensional plot. Show a view in which the clusters are well-separated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gK1ByMMUJKt"
      },
      "outputs": [],
      "source": [
        "colors = ['r','k','y','g','b','m','c','darkviolet']\n",
        "num_reaches_per_angle = 91;\n",
        "\n",
        "fig = plt.figure()\n",
        "ax  = fig.add_subplot(projection='3d')\n",
        "\n",
        "for reachAngle in range(8):\n",
        "  indx = np.arange(0,num_reaches_per_angle,1)+(reachAngle)*num_reaches_per_angle\n",
        "  X = Xplan_centered[indx,:]\n",
        "  ax.scatter(X@U[:,0],X@U[:,1],X@U[:,2],'o', color=colors[reachAngle])\n",
        "\n",
        "ax.set_xlabel('PC 1')\n",
        "ax.set_ylabel('PC 2')\n",
        "ax.set_zlabel('PC 3')\n",
        "\n",
        "plt.title('Reach data projected into three-dimensional PC space')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_DWy6qnUucc"
      },
      "source": [
        "[EXERCISE 1d] Define a matrix $U_M$ containing the top 3 eigenvectors (i.e. the top 3 PCs), where $U(d,m)$ indicates the contribution of the dth neuron to the mth principal component. Show the values in $U$ as a heatmap. Are there are any obvious groupings among the neurons in each column of $U$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPZ63HKkjQ8b"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "U3  = U[:,:3]\n",
        "print(U3.shape)\n",
        "b   = plt.imshow(U3, aspect='auto')\n",
        "fig.colorbar(b)\n",
        "plt.xticks([0,1,2],[1,2,3])\n",
        "plt.xlabel('Principal component #')\n",
        "plt.ylabel('Neuron #')\n",
        "plt.title('Heat map of top three principal component directions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q-XinpByVMN0"
      },
      "outputs": [],
      "source": [
        "# #@title Double click to see solution {display-mode: \"form\" }\n",
        "# fig = plt.figure()\n",
        "# U3  = U[:,0:3]\n",
        "# b   = plt.imshow(U3, aspect='auto')\n",
        "# fig.colorbar(b)\n",
        "# plt.xticks([0,1,2],[1,2,3])\n",
        "# plt.xlabel('Principal component #')\n",
        "# plt.ylabel('Neuron #')\n",
        "# plt.title('Heat map of top three principal component directions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j-VotJCbga9"
      },
      "source": [
        "Most elements of the top three eigenvectors are relatively small, with absolute values less than 0.15, indicating that those neurons contibute relatively little to the corresponding principal component. The relatively large elements of a particular eigenvector, with absolute values greater than 0.15, indicate clusters of neurons working together along the direction defined by the eigenvector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skdm8bKi5e8y"
      },
      "source": [
        "---\n",
        "# About the author (feel free to contact)\n",
        "\n",
        "## Joana Soldado Magraner\n",
        "- Postdoctoral researcher at Carnegie Mellon University, Pittsburgh, US.\n",
        "- I study the computational properties of prefrontal cortex circuits.\n",
        "- I am also one of the organizer of this TReND-CaMinA course.\n",
        "- Feel free to contact me: jsoldadomagraner@cmu.edu"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
